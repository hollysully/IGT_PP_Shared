---
title: "Single-Parameter Model"
output: html_document
---


# -------------------------------------------
# Setup
## Load Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rstan)
library(hBayesDM)
library(bayesplot)
library(here)
library(miscTools)
# library(wBoot)
library(cmdstanr)
library(stringi)
library(ggpp)
library(lemon)
source(here("1_IGT_PP", "Code", "R", "3_other", "helpful_functions.R"))
library(MASS)
library(ggh4x)
library(grid)
```


## Functions
```{r, eval = T}
#------------------------------------------------------------------------------
# USE SOFTMAX TO OBTAIN CHOICE PROBABILITIES - USED IN SIMULATIONS
softmax = function(values){
  return(exp(values) / sum(exp(values)))
}

data = data.frame()

#------------------------------------------------------------------------------
# SIMULATION FUNCTION
simulate_RL = function(learning_rate = .5, n_trials = 100,
                       Sr_probs = c(.3, .7), label = "") {
  A = learning_rate
  utility = rep(0,2)
    
  for(t in 1:n_trials){
    prob = softmax(c(utility[1], utility[2]))
    
    choice = sample(c(1,2), 1, prob = prob)
    
    outcome = rbinom(1, 1, Sr_probs[choice])
    
    data = data.frame(sim = label,
                      A = A,
                      trial = t,
                      prob_1 = prob[1],
                      prob_2 = prob[2],
                      utility_1 = utility[1],
                      utility_2 = utility[2],
                      outcome = outcome,
                      choice = choice) %>% 
      bind_rows(data)
    
    utility[choice] = utility[choice] + A * (outcome - utility[choice])
  }
  data %>%
    return()
}
```


## Test Functions
```{r, eval = F}
set.seed(20240807)
test_data = bind_rows(simulate_RL(learning_rate = .2, label = "hi"),
                     simulate_RL(learning_rate = .05, label = "lo")) %>% 
  pivot_longer(ends_with(c("1", "2")), names_to = "variable", values_to = "value") %>% 
  separate("variable", into = c("variable", "option")) %>% 
  pivot_wider(names_from = "variable", values_from = "value")


ggplot(test_data, aes(x = trial, y = utility, color = option)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~sim)


ggplot(test_data, aes(x = trial, y = prob, color = option)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~sim)


ggplot(test_data, aes(x = trial, y = utility, color = sim)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~option)


ggplot(test_data, aes(x = trial, y = prob, color = sim)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~option)
```


# -------------------------------------------
# Simulate Parameters
## Setup
```{r, eval = T}
# setup for how much data will be generated - i.e., n_sessions x N = # of observations
S = 5   # number of sessions
N = 100 # number of participants

residual_sd = 1 # standard deviation of residuals

# group-level parameters
mu_intercept_UT = qnorm(.1) # mean untransformed intercept for learning rate
sd_intercept_UT = 1         # standard deviation of intercepts

mu_beta_UT = .5 # slope effect for session
sd_beta_UT = 1  # standard deviation of intercepts

# building variance-covariance matrix
int_slope_R = .5 # correlation between intercepts and slopes
R = matrix(data = c(1, int_slope_R, int_slope_R, 1), nrow = 2, ncol = 2) # correlation matrix
SD = diag(c(sd_intercept_UT, sd_beta_UT)) # SD matrix
VC = SD%*%R%*%SD # variance-covariance matrix
```


## Simulation
```{r, eval = T}
set.seed(20240611)

# simulate & plot person-level intercept & slope parameters
parameters = mvrnorm(N, mu = c(mu_intercept_UT, mu_beta_UT), Sigma = VC) # draw from MVT Normal
hist(parameters[,1])
hist(parameters[,2])

# combine the parameters into the untransformed As (i.e., on normal distribution scale)
A_UTs = parameters[,1] + parameters[,2]%*%t(1:S-1) + replicate(5, rnorm(N, 0, residual_sd))
As = pnorm(A_UTs)

# plot untransformed As
plot(rep(1:S, N), A_UTs) +
  points(1:S, apply(A_UTs, 2, mean),
         pch = 15, col = "red", cex = 1.5)

# plot transformed As
plot(rep(1:S, N), pnorm(A_UTs)) +
  points(1:S, apply(As, 2, mean),
         pch = 15, col = "red", cex = 1.5)

# run MLM to see if it captures changes across time
data.frame(ID = 1:N, session = A_UTs) %>%
  pivot_longer(starts_with("session"), names_to = "session", values_to = "A_UT",
               names_prefix = "session.", names_transform = list(session = as.numeric)) %>%
  mutate(A = pnorm(A_UT), session = session-1) %>%
  lmerTest::lmer(A_UT ~ session + (session|ID), data = .) %>%
  summary()
```


# -------------------------------------------
# Simulate Choice Data
## Generate Data
```{r}
set.seed(20240807)

sim_data = data.frame()

for(i in 1:N){
  for(s in 1:S){
    sim_data = simulate_RL(learning_rate = As[i,s], 
                           label = as.numeric(paste(s, i, sep = "0"))) %>% 
      mutate(ID = i, session = s) %>% 
      bind_rows(sim_data)
  }
}
```


## Convert to Stan Data
```{r}
Tr = max(sim_data$trial)
choice = array(-1, dim = c(N,Tr,S))
outcome = array(0, dim = c(N,Tr,S))

for(s in 1:S){
  for(i in 1:N){
    cur_data = filter(sim_data, session == s, ID == i) %>% 
      arrange(trial)
    choice[i,,s] = cur_data$choice
    outcome[i,,s] = cur_data$outcome
  }
}


stan_data = list(N = N,
                 T = Tr,
                 S = S,
                 choice = choice,
                 outcome = outcome)
```


# -------------------------------------------
# Fitting RL Model
## Check Model
```{r, eval = F}
model_code = cmdstan_model(here("1_Long_Comp", "Code", "Stan", "Single_Parameter_Model.stan"),
                           compile = F)

model_code$check_syntax(quiet = T)
```


## Fit Model
```{r}
# Compile model
RL_model = stan_model(here("1_Long_Comp", "Code", "Stan", "Single_Parameter_Model.stan"))


# -----------------------------------------------------------------------------------
# Fit model
RL_fit = sampling(RL_model, 
                  data   = stan_data, 
                  iter   = 5000, 
                  warmup = 1000, 
                  chains = 1, 
                  cores  = 4,
                  seed   = 43210,
                  save_warmup = F)
saveRDS(RL_fit, here("1_Long_Comp", "Data", "2_Fitted", "Single_Parameter_Model.stan"))
```


## Extract Posteriors
```{r}
# -----------------------------------------------------------------------------------
# save posteriors
RL_posteriors = extract(RL_fit)
saveRDS(RL_posteriors, here("1_Long_Comp", "Data", "2_Fitted", "RL_posteriors.RDS"))
  
# -----------------------------------------------------------------------------------
# save rhats
RL_rhats = rhat(RL_fit, pars = c("gamma00", "gamma10", "R", "R_chol", "sigma_U", "z_U",
                                 "beta0", "beta1", "U", "A", "utility", "R_A")) %>%
                  data.frame() %>% mutate(parameter = rownames(.))
saveRDS(RL_rhats, here("1_Long_Comp", "Data", "2_Fitted", "RL_rhats.RDS"))
```


```{r}
RL_posteriors = readRDS(here("1_Long_Comp", "Data", "2_Fitted", "RL_posteriors.RDS"))
RL_rhats = readRDS(here("1_Long_Comp", "Data", "2_Fitted", "RL_rhats.RDS"))
```


# -------------------------------------------
# Assess Recovery
## Group-Level Parameters
```{r}
paste("Group-Level Intercept:",
      "True =", round(mu_intercept_UT, 3), "&",
      "Estimated =", round(mean(RL_posteriors$gamma00), 3))
paste("Group-Level Slope:",
      "True =", round(mu_beta_UT, 3), "&",
      "Estimated =", round(mean(RL_posteriors$gamma10), 3))


paste("Residual SD:",
      "True =", round(residual_sd, 3), "&",
      "Estimated =", round(mean(RL_posteriors$R), 3))
paste("SD for Intercepts:",
      "True =", round(sd_intercept_UT, 3), "&",
      "Estimated =", round(mean(RL_posteriors$sigma_U[,1]), 3))
paste("SD for Slopes:",
      "True =", round(sd_beta_UT, 3), "&",
      "Estimated  =", round(mean(RL_posteriors$sigma_U[,2]), 3))


paste("Correlation Between RIs & RSs:",
      "True =", round(int_slope_R, 3), "&",
      "Estimated =", round(mean(RL_posteriors$R_A[,2,1]), 3))
```


## Person-Level Parameters
```{r}
regression_parameters = data.frame(true_beta0 = parameters[,1],
                                   true_beta1 = parameters[,2],
                                   est_beta0 = apply(RL_posteriors$beta0, 2, mean),
                                   est_beta1 = apply(RL_posteriors$beta1, 2, mean))


est_A_UTs = data.frame(iteration = 1:nrow(RL_posteriors$beta0),
                      beta0 = RL_posteriors$beta0,
                      beta1 = RL_posteriors$beta1) %>% 
  pivot_longer(cols = starts_with("beta"), names_to = c("parameter", "ID"),
               values_to = "estimate", names_sep = "\\.",
               names_transform = list("ID" = as.integer)) %>%
  pivot_wider(names_from = "parameter", values_from = "estimate") %>% 
  cbind(data.frame(session1 = 1, session2 = 2, session3 = 3, 
                   session4 = 4, session5 = 5)) %>% 
  pivot_longer(starts_with("session"), names_to = "discard", values_to = "session") %>% 
  mutate(est_A_UT = beta0 + beta1*(session-1)) %>% 
  group_by(ID, session) %>% 
  summarise(est_A_UT = mean(est_A_UT))


RL_parameters = data.frame(ID = 1:N,
                           true_A = As,
                           true_A_UT = A_UTs,
                           est_A = t(apply(RL_posteriors$A, c(2, 3), mean))) %>% 
  pivot_longer(starts_with(c("true","est")),
               names_to = c("parameter", "session"), values_to = "estimate",
               names_sep = "\\.", names_transform = list("session" = as.integer)) %>% 
  pivot_wider(names_from = "parameter", values_from = "estimate") %>% 
  left_join(est_A_UTs) %>% 
  pivot_longer(starts_with(c("true", "est")),
               names_to = "parameter", values_to = "estimate") %>% 
  mutate(type = case_when(str_detect(parameter, "true") ~ "true", T ~ "est"),
         parameter = str_remove(parameter, "true_|est_")) %>% 
  pivot_wider(names_from = "type", values_from = "estimate")
```


```{r}
person_level_plot = RL_parameters %>% 
    mutate(session_lab = case_when(parameter == "A_UT" ~ paste0("T", session), T ~ "")) %>% 
    ggplot(aes(x = true, y = est)) +
      ggpp::geom_text_npc(aes(npcx = "right", npcy = "bottom", label = session_lab),
                          hjust = .95, vjust = .25, size = 7) +
      geom_point() +
      geom_smooth(method = "lm", formula = y~x, se = F) +
      scale_x_continuous(expand = expansion(mult = .025)) +
      scale_y_continuous(expand = expansion(mult = .025)) +
      labs(x = "True Person-Level Estimate", y = "Estimated Person-Level Estimate") +
      theme_classic() +
      theme(axis.text = element_blank(),
            axis.title = element_text(size = 16),
            strip.text = element_blank(),
            plot.margin = unit(c(1, .5, .5, .5), units = "cm")) +
      lemon::facet_rep_wrap(session~parameter, scales = "free", ncol = 2)

tiff(here("1_Long_Comp", "Figs_Tables",
          "RL True v Est Person-Level Parameters.tiff"),
     width = 10, height = 22, units = "cm", res = 300)

  # plot
  grid.newpage()
  pushViewport(viewport(x = .5, y = .5, width = 1, height = 1))
  grid.draw(person_level_plot)
  
  # text
  grid.text(c(expression(italic(A)), expression(paste("Unbounded ", italic(A)))),
            x = c(.325, .75), y = .98,
            gp = gpar(fontsize = 18))
  
dev.off()
```







