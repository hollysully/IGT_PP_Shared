---
title: "Single-Parameter Model"
output: html_document
---


# -------------------------------------------
# Setup
## Load Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rstan)
library(hBayesDM)
library(bayesplot)
library(here)
library(miscTools)
library(wBoot)
library(cmdstanr)
library(stringi)
library(ggpp)
library(lemon)
source(here("1_IGT_PP", "Code", "R", "3_other", "helpful_functions.R"))
library(MASS)
library(ggh4x)
library(grid)
```


## Functions
```{r, eval = T}
#------------------------------------------------------------------------------
# USE SOFTMAX TO OBTAIN CHOICE PROBABILITIES - USED IN SIMULATIONS
softmax = function(values){
  return(exp(values) / sum(exp(values)))
}

data = data.frame()

#------------------------------------------------------------------------------
# SIMULATION FUNCTION
simulate_RL = function(learning_rate = .5, n_trials = 100,
                       Sr_probs = c(.3, .7), label = "") {
  A = learning_rate
  utility = rep(0,2)
    
  for(t in 1:n_trials){
    prob = softmax(c(utility[1], utility[2]))
    
    choice = sample(c(1,2), 1, prob = prob)
    
    outcome = rbinom(1, 1, Sr_probs[choice])
    
    data = data.frame(sim = label,
                      A = A,
                      trial = t,
                      prob_1 = prob[1],
                      prob_2 = prob[2],
                      utility_1 = utility[1],
                      utility_2 = utility[2],
                      outcome = outcome,
                      choice = choice) %>% 
      bind_rows(data)
    
    utility[choice] = utility[choice] + A * (outcome - utility[choice])
  }
  data %>%
    return()
}
```


## Test Functions
```{r, eval = F}
set.seed(20240807)
test_data = bind_rows(simulate_RL(learning_rate = .2, label = "hi"),
                     simulate_RL(learning_rate = .05, label = "lo")) %>% 
  pivot_longer(ends_with(c("1", "2")), names_to = "variable", values_to = "value") %>% 
  separate("variable", into = c("variable", "option")) %>% 
  pivot_wider(names_from = "variable", values_from = "value")


ggplot(test_data, aes(x = trial, y = utility, color = option)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~sim)


ggplot(test_data, aes(x = trial, y = prob, color = option)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~sim)


ggplot(test_data, aes(x = trial, y = utility, color = sim)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~option)


ggplot(test_data, aes(x = trial, y = prob, color = sim)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  facet_rep_grid(.~option)
```


# -------------------------------------------
# Simulate Parameters
## Setup
```{r, eval = T}
# setup for how much data will be generated - i.e., n_sessions x N = # of observations
S = 5   # number of sessions
N = 100 # number of participants

residual_sd = 1 # standard deviation of residuals

# group-level parameters
mu_intercept_UT = qnorm(.1) # mean untransformed intercept for learning rate
sd_intercept_UT = 1         # standard deviation of intercepts

mu_beta_UT = .5 # slope effect for session
sd_beta_UT = 1  # standard deviation of intercepts

# building variance-covariance matrix
int_slope_R = .5 # correlation between intercepts and slopes
R = matrix(data = c(1, int_slope_R, int_slope_R, 1), nrow = 2, ncol = 2) # correlation matrix
SD = diag(c(sd_intercept_UT, sd_beta_UT)) # SD matrix
VC = SD%*%R%*%SD # variance-covariance matrix
```


## Simulation
```{r, eval = T}
set.seed(20240611)

# simulate & plot person-level intercept & slope parameters
parameters = mvrnorm(N, mu = c(mu_intercept_UT, mu_beta_UT), Sigma = VC) # draw from MVT Normal
hist(parameters[,1])
hist(parameters[,2])

# combine the parameters into the untransformed As (i.e., on normal distribution scale)
A_UTs = parameters[,1] + parameters[,2]%*%t(1:S-1) + replicate(5, rnorm(N, 0, residual_sd))
As = pnorm(A_UTs)

# plot untransformed As
plot(rep(1:S, N), A_UTs) +
  points(1:S, apply(A_UTs, 2, mean),
         pch = 15, col = "red", cex = 1.5)

# plot transformed As
plot(rep(1:S, N), pnorm(A_UTs)) +
  points(1:S, apply(As, 2, mean),
         pch = 15, col = "red", cex = 1.5)

# run MLM to see if it captures changes across time
data.frame(ID = 1:N, session = A_UTs) %>%
  pivot_longer(starts_with("session"), names_to = "session", values_to = "A_UT",
               names_prefix = "session.", names_transform = list(session = as.numeric)) %>%
  mutate(A = pnorm(A_UT), session = session-1) %>%
  lmerTest::lmer(A_UT ~ session + (session|ID), data = .) %>%
  summary()
```


# -------------------------------------------
# Simulate Choice Data
## Generate Data
```{r}
set.seed(20240807)

sim_data = data.frame()

for(i in 1:N){
  for(s in 1:S){
    sim_data = simulate_RL(learning_rate = As[i,s], 
                           label = as.numeric(paste(s, i, sep = "0"))) %>% 
      mutate(ID = i, session = s) %>% 
      bind_rows(sim_data)
  }
}
```


## Convert to Stan Data
```{r}
Tr = max(sim_data$trial)
choice = array(-1, dim = c(N,Tr,S))
outcome = array(0, dim = c(N,Tr,S))

for(s in 1:S){
  for(i in 1:N){
    cur_data = filter(sim_data, session == s, ID == i) %>% 
      arrange(trial)
    choice[i,,s] = cur_data$choice
    outcome[i,,s] = cur_data$outcome
  }
}


stan_data = list(N = N,
                 T = Tr,
                 S = S,
                 choice = choice,
                 outcome = outcome)
```


# -------------------------------------------
# Fit RL Model
```{r}
model_code = cmdstan_model(here("1_Long_Comp", "Code", "Stan", "Single_Parameter_Model.stan"),
                           compile = F)

model_code$check_syntax(quiet = T)
```

```{r}
# Compile model
RL_model = stan_model(here("1_Long_Comp", "Code", "Stan", "Single_Parameter_Model.stan"))


# -----------------------------------------------------------------------------------
# Fit model
RL_fit = sampling(RL_model, 
                  data   = stan_data, 
                  iter   = 2000, 
                  warmup = 1000, 
                  chains = 1, 
                  cores  = 4,
                  seed   = 43210,
                  save_warmup = F)
saveRDS(RL_fit, here("1_Long_Comp", "Data", "2_Fitted", "Single_Parameter_Model.stan"))
```


```{r}
# -----------------------------------------------------------------------------------
# save posteriors
RL_posteriors = extract(RL_fit)
saveRDS(RL_posteriors, here("1_Long_Comp", "Data", "2_Fitted", "RL_posteriors.RDS"))
  
# -----------------------------------------------------------------------------------
# save rhats
RL_rhats = rhat(RL_posteriors, pars = focal_parameters) %>%
  data.frame() %>% mutate(parameter = rownames(.)) %>% 
  saveRDS(here("1_Long_Comp", "Data", "2_Fitted", "RL_rhats.RDS"))
```







