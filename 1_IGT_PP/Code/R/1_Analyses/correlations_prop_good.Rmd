---
title: "Correlations"
subtitle: "Self-Report w/ ORL Parameters"
output: html_document
---



# -----------------------------------------------
# Setup
## Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(haven)
library(here)
library(wBoot)
```



## Set Seed
```{r}
set.seed(20230320)
```



## Self-Report Data
```{r}
sr_sess1 = read_sav(here("1_IGT_PP", "Data", "0_Raw", "MergedQuest_3.21.16-Session1.sav"),
                    col_select = c("ID", "sex", "race", "Ethnicity",
                                   "bastot", "basdrive", "basfunsk",
                                   "basrewres", "bis", "panas_pa",
                                   "panas_na", "masqGDA", "masqAA", "masqGDD",
                                   "masqAD", "shaps_tot", "prdep_tot")) %>% 
  # mutate(session = 1) %>%
  filter(ID >= 2049,                          # Subset PP participants
         ID != 2059,                          # Remove participant that played old IFT
         ID != 2083)                          # Remove participant that had no task data

sr_sess2 = read_sav(here("1_IGT_PP", "Data", "0_Raw", "MergedQuest_3.21.16-Session2.sav"),
                    col_select = c("ID", "bastot", "basdrive", "basfunsk",
                                   "basrewres", "bis", "panas_pa",
                                   "panas_na", "shaps_tot")) %>% 
  # mutate(session = 2) %>%
  filter(ID >= 2049,                          # Subset PP participants
         ID != 2059,                          # Remove participant that played old IFT
         ID != 2083,                          # Remove participant that had no task data
         !ID %in% c(2057, 2063, 2064,         # Remove participants that didn't do session 2
                    2067, 2086, 2090,
                    2093, 2094, 2096, 2098))

```
<!-- ------------------------------------------------------------------------------------------ -->
* Demographics
  + ID, sex, race, Ethnicity
  
* Behavioral Activation Scale
  + bastot    = ?
  + basdrive  = Drive subscale: measures persistent pursuit of goals
  + basfunsk  = Fun Seeking subscale: measures desire for and approach towards new rewards
  + basrewres = Reward Responsiveness subscale: measures positive responses to the anticipation or consummation of rewards
  
* Behavioral Inhibition Scale: measures sensitivity to negatively-valenced events
  + bis

* Positive Affect/Negative Affect Schedules: measures state-level mood
  + panas_pa = Positive Affect
  + panas_na = Negative Affect

* Mood and Anxiety Symptom Questionnaire (MASQ): assesses internalizing symptoms experienced in past week
  + masqGDA = General Distress Anxiety subscale: measures general anxious mood
  + masqAA  = Anxious Arousal subscale: measures somatic hyperarousal
  + masqGDD = General Distress Depression subscale: measures general depressed mood
  + masqAD  = Anhedonic Depression subscale: measures low positive affect

* Snaith-Hamilton Pleasure Scale: measures ability to experience pleasure in last few days
  + shaps_tot

* Patient-Reported Outcomes Measurement Information System: assesses symptoms of depression experienced in past week
  + prdep_tot

<!-- ------------------------------------------------------------------------------------------ -->



## Choice Data
```{r}
session1_data <- read.csv((here("1_IGT_PP", "Data", "1_Preprocessed", "Sess1_IGT.csv"))) %>% 
  mutate(session = 1)
session2_data <- read.csv((here("1_IGT_PP", "Data", "1_Preprocessed", "Sess2_IGT.csv"))) %>% 
  mutate(session = 2)

combined_data = bind_rows(session1_data, session2_data) %>% 
  mutate(play = recode(ydata, "2" = 0, "1" = 1),
         version = case_when(str_detect(ExperimentName, "1") ~ 1,
                             str_detect(ExperimentName, "2") ~ 2)) %>% 
  group_by(Subject, session) %>% 
  mutate(trial = 1,
         trial = cumsum(trial),
         stim = recode(stim, "1" = "A", "2" = "B", "3" = "C", "4" = "D")) %>% 
  filter(stim == "D" | stim == "C") %>% 
  group_by(Subject, session) %>% 
  reframe(prop_good = mean(play)) %>% 
  pivot_wider(names_from = "session", values_from = "prop_good", names_prefix = "session_") %>% 
  select(ID = Subject, everything())

card_proportions = bind_rows(session1_data, session2_data) %>% 
  mutate(play = recode(ydata, "2" = 0, "1" = 1),
         version = case_when(str_detect(ExperimentName, "1") ~ 1,
                             str_detect(ExperimentName, "2") ~ 2)) %>% 
  group_by(Subject, session) %>% 
  mutate(trial = 1,
         trial = cumsum(trial),
         stim = recode(stim, "1" = "A", "2" = "B", "3" = "C", "4" = "D")) %>% 
  group_by(Subject, session, stim) %>% 
  reframe(prop_good = mean(play)) %>% 
  pivot_wider(names_from = "session", values_from = "prop_good", names_prefix = "session_") %>% 
  select(ID = Subject, everything())
```



# -----------------------------------------------
# Proportion Good
## Test-Retest
```{r}
cor(combined_data$session_1, combined_data$session_2,
    use = "pairwise.complete.obs")
```



## Self-Report Correlations
```{r}
correlations = data.frame()
```



### Individual-Subject Mus
```{r}
overall_correlations = data.frame()

sr_prop = bind_rows(sr_sess1, sr_sess2) %>% 
  select(-c(sex, race, Ethnicity)) %>%   # Remove columns that we don't need
  pivot_longer(c("bastot", "basdrive", "basfunsk",
               "basrewres", "bis", "panas_pa",
               "panas_na", "masqGDA", "masqAA", "masqGDD",
               "masqAD", "shaps_tot", "prdep_tot"),
               names_to = "scale", values_to = "score") %>% 
  group_by(ID, scale) %>% 
  reframe(score = mean(score, na.rm = T)) %>% 
  left_join(combined_data)
  
# Loop through each scale from session 2
for(curr_scale in unique(sr_prop$scale)){
    
    curr_data = sr_prop %>%
      filter(scale == curr_scale) # Subset data
    
    curr_score = curr_data$score            # Subset scale data
    curr_estimate = ifelse(is.na(curr_data$session_2),
                           curr_data$session_1,
                           (curr_data$session_1 + curr_data$session_2) / 2)  # Subset estimate for parameter
    # Run the boot-strapped correlation between the current scale and the current parameter
    curr_cor = boot.cor.bca(x = curr_score, y = curr_estimate,
                            null.hyp = NULL,
                            alternative = c("two.sided", "less", "greater"),
                            conf.level = 0.95, type = NULL, R = 9999)
    
    curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
      separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
      # Remove parentheses and turn CIs into numerics
      mutate(lower = as.numeric(str_remove(lower, "[(]")),
             upper = as.numeric(str_remove(upper, "[)]")))
    
    # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
    overall_correlations = bind_rows(overall_correlations,
                             data.frame(parameter = "proportion_good",
                                        scale = curr_scale,
                                        r = curr_cor$Observed,
                                        lower_ci = curr_ci$lower[1],
                                        upper_ci = curr_ci$upper[1]))
}
```



### Session 1 Self-Report w/ Session 1 & 2 ORL Parameters
```{r}
# Loop through each scale from session 1
for(scale in c("bastot", "basdrive", "basfunsk",
               "basrewres", "bis", "panas_pa",
               "panas_na", "masqGDA", "masqAA", "masqGDD",
               "masqAD", "shaps_tot", "prdep_tot")){
    
    curr_data = combined_data %>%
      left_join(sr_sess1) %>%                    # Join scales to orl parameter
      select(-c(sex, race, Ethnicity)) %>%       # Remove columns that we don't need
      na.omit()                                  # Remove rows with NAs
    
    curr_scale = curr_data[[scale]]              # Subset scale data
    curr_estimate = curr_data[["session_1"]] # Subset estimate for parameter
    # Run the boot-strapped correlation between the current scale and the current parameter
    curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                            null.hyp = NULL,
                            alternative = c("two.sided", "less", "greater"),
                            conf.level = 0.95, type = NULL, R = 9999)
    
    curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
      separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
      # Remove parentheses and turn CIs into numerics
      mutate(lower = as.numeric(str_remove(lower, "[(]")),
             upper = as.numeric(str_remove(upper, "[)]")))
    
    # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
    correlations = bind_rows(correlations,
                             data.frame(parameter_session = 1,
                                        scale_session = 1,
                                        parameter = "proportion_good",
                                        scale = scale,
                                        r = curr_cor$Observed,
                                        lower_ci = curr_ci$lower[1],
                                        upper_ci = curr_ci$upper[1]))
    
    curr_data = combined_data %>%
      left_join(sr_sess1) %>%                    # Join scales to orl parameter
      select(-c(sex, race, Ethnicity)) %>%       # Remove columns that we don't need
      na.omit()                                  # Remove rows with NAs
    
    curr_scale = curr_data[[scale]]              # Subset scale data
    curr_estimate = curr_data[["session_2"]] # Subset estimate for parameter
    # Run the boot-strapped correlation between the current scale and the current parameter
    curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                            null.hyp = NULL,
                            alternative = c("two.sided", "less", "greater"),
                            conf.level = 0.95, type = NULL, R = 9999)
    
    curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
      separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
      # Remove parentheses and turn CIs into numerics
      mutate(lower = as.numeric(str_remove(lower, "[(]")),
             upper = as.numeric(str_remove(upper, "[)]")))
    
    # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
    correlations = bind_rows(correlations,
                             data.frame(parameter_session = 2,
                                        scale_session = 1,
                                        parameter = "proportion_good",
                                        scale = scale,
                                        r = curr_cor$Observed,
                                        lower_ci = curr_ci$lower[1],
                                        upper_ci = curr_ci$upper[1]))
}
```



### Session 2 Self-Report w/ Session 1 & 2 ORL Parameters
```{r}
# Loop through each scale from session 2
for(scale in c("bastot", "basdrive", "basfunsk",
               "basrewres", "bis", "panas_pa",
               "panas_na", "shaps_tot")){
    
    curr_data = combined_data %>% 
      left_join(sr_sess2) %>%                    # Join scales to orl parameter
      na.omit()                                  # Remove rows with NAs
    
    curr_scale = curr_data[[scale]]              # Subset scale data
    curr_estimate = curr_data[["session_1"]] # Subset estimate for parameter
    # Run the boot-strapped correlation between the current scale and the current parameter
    curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                            null.hyp = NULL,
                            alternative = c("two.sided", "less", "greater"),
                            conf.level = 0.95, type = NULL, R = 9999)
    
    curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
      separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
      # Remove parentheses and turn CIs into numerics
      mutate(lower = as.numeric(str_remove(lower, "[(]")),
             upper = as.numeric(str_remove(upper, "[)]")))
    
    # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
    correlations = bind_rows(correlations,
                             data.frame(parameter_session = 1,
                                        scale_session = 2,
                                        parameter = "proportion_good",
                                        scale = scale,
                                        r = curr_cor$Observed,
                                        lower_ci = curr_ci$lower[1],
                                        upper_ci = curr_ci$upper[1]))
    
    curr_data = combined_data %>%             # Subset orl parameter
      left_join(sr_sess2) %>%                    # Join scales to orl parameter
      na.omit()                                  # Remove rows with NAs
    
    curr_scale = curr_data[[scale]]              # Subset scale data
    curr_estimate = curr_data[["session_2"]] # Subset estimate for parameter
    # Run the boot-strapped correlation between the current scale and the current parameter
    curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                            null.hyp = NULL,
                            alternative = c("two.sided", "less", "greater"),
                            conf.level = 0.95, type = NULL, R = 9999)
    
    curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
      separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
      # Remove parentheses and turn CIs into numerics
      mutate(lower = as.numeric(str_remove(lower, "[(]")),
             upper = as.numeric(str_remove(upper, "[)]")))
    
    # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
    correlations = bind_rows(correlations,
                             data.frame(parameter_session = 2,
                                        scale_session = 2,
                                        parameter = "proportion_good",
                                        scale = scale,
                                        r = curr_cor$Observed,
                                        lower_ci = curr_ci$lower[1],
                                        upper_ci = curr_ci$upper[1]))
}
```



## Format Correlations
### By Session
```{r}
formatted_correlations = correlations %>% 
  # Identify CIs that DO NOT overlap with 0
  mutate(sig = case_when(lower_ci < 0 & upper_ci < 0 ~ "*",
                         lower_ci > 0 & upper_ci > 0 ~ "*",
                         T ~ ""),
         # Format numerics
         r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = "."),
         lower_ci = str_replace(format(round(lower_ci, 2), nsmall = 2), "0.", replacement = "."),
         upper_ci = str_replace(format(round(upper_ci, 2), nsmall = 2), "0.", replacement = "."),
         # Concatenating correlations and CIs
         estimate = paste(r, " (", lower_ci, ", ", upper_ci, ")", sig,
                          sep = "")) %>% 
  select(-c(sig, r, lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = c("parameter", "parameter_session", "scale_session"), values_from = estimate,
              values_fill = "")

write.csv(formatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "proportion_formatted_correlations.csv"))
```



### Overall
```{r}
formatted_correlations = overall_correlations %>% 
  # Identify CIs that DO NOT overlap with 0
  mutate(sig = case_when(lower_ci < 0 & upper_ci < 0 ~ "*",
                         lower_ci > 0 & upper_ci > 0 ~ "*",
                         T ~ ""),
         # Format numerics
         r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = "."),
         lower_ci = str_replace(format(round(lower_ci, 2), nsmall = 2), "0.", replacement = "."),
         upper_ci = str_replace(format(round(upper_ci, 2), nsmall = 2), "0.", replacement = "."),
         # Concatenating correlations and CIs
         estimate = paste(r, " (", lower_ci, ", ", upper_ci, ")", sig,
                          sep = "")) %>% 
  select(-c(sig, r, lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = "parameter", values_from = estimate,
              values_fill = "")

write.csv(formatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "proportion_formatted_overall_correlations.csv"))
```



## Unformatted Correlations
```{r}
unformatted_correlations = correlations %>% 
  # format correlations
  mutate(r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = ".")) %>% 
  select(-c(lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = c("parameter", "parameter_session", "scale_session"), values_from = r,
              values_fill = "")

write.csv(unformatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "proportion_unformatted_correlations.csv"))
```



# -----------------------------------------------
# Card Proportions
## Test-Retest
```{r}
for(card in c("A", "B", "C", "D")){
  print(paste(card, ": ", round(cor(filter(card_proportions, stim == card)$session_1, 
                                    filter(card_proportions, stim == card)$session_2,
                                    use = "pairwise.complete.obs"), 2), sep = ""))
}
```



## Self-Report Correlations
```{r}
correlations = data.frame()
```



### Individual-Subject Mus
```{r}
overall_correlations = data.frame()

sr_prop = bind_rows(sr_sess1, sr_sess2) %>% 
  select(-c(sex, race, Ethnicity)) %>%   # Remove columns that we don't need
  pivot_longer(c("bastot", "basdrive", "basfunsk",
               "basrewres", "bis", "panas_pa",
               "panas_na", "masqGDA", "masqAA", "masqGDD",
               "masqAD", "shaps_tot", "prdep_tot"),
               names_to = "scale", values_to = "score") %>% 
  group_by(ID, scale) %>% 
  reframe(score = mean(score, na.rm = T)) %>% 
  left_join(card_proportions)

for(card in c("A", "B", "C", "D")){
  # Loop through each scale from session 2
  for(curr_scale in unique(sr_prop$scale)){
      
      curr_data = sr_prop %>%
        filter(scale == curr_scale & stim == card) # Subset data
      
      curr_score = curr_data$score            # Subset scale data
      curr_estimate = ifelse(is.na(curr_data$session_2),
                           curr_data$session_1,
                           (curr_data$session_1 + curr_data$session_2) / 2)  # Subset estimate for parameter
      # Run the boot-strapped correlation between the current scale and the current parameter
      curr_cor = boot.cor.bca(x = curr_score, y = curr_estimate,
                              null.hyp = NULL,
                              alternative = c("two.sided", "less", "greater"),
                              conf.level = 0.95, type = NULL, R = 9999)
      
      curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
        separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
        # Remove parentheses and turn CIs into numerics
        mutate(lower = as.numeric(str_remove(lower, "[(]")),
               upper = as.numeric(str_remove(upper, "[)]")))
      
      # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
      overall_correlations = bind_rows(overall_correlations,
                               data.frame(parameter = "proportion_good",
                                          card = card,
                                          scale = curr_scale,
                                          r = curr_cor$Observed,
                                          lower_ci = curr_ci$lower[1],
                                          upper_ci = curr_ci$upper[1]))
  }
}
```



### Session 1 Self-Report w/ Session 1 & 2 ORL Parameters
```{r}
for(card in c("A", "B", "C", "D")){
  # Loop through each scale from session 1
  for(scale in c("bastot", "basdrive", "basfunsk",
                 "basrewres", "bis", "panas_pa",
                 "panas_na", "masqGDA", "masqAA", "masqGDD",
                 "masqAD", "shaps_tot", "prdep_tot")){
      
      curr_data = card_proportions %>%
        filter(stim == card) %>% 
        left_join(sr_sess1) %>%                    # Join scales to orl parameter
        select(-c(sex, race, Ethnicity)) %>%       # Remove columns that we don't need
        na.omit()                                  # Remove rows with NAs
      
      curr_scale = curr_data[[scale]]              # Subset scale data
      curr_estimate = curr_data[["session_1"]] # Subset estimate for parameter
      # Run the boot-strapped correlation between the current scale and the current parameter
      curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                              null.hyp = NULL,
                              alternative = c("two.sided", "less", "greater"),
                              conf.level = 0.95, type = NULL, R = 9999)
      
      curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
        separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
        # Remove parentheses and turn CIs into numerics
        mutate(lower = as.numeric(str_remove(lower, "[(]")),
               upper = as.numeric(str_remove(upper, "[)]")))
      
      # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
      correlations = bind_rows(correlations,
                               data.frame(card = card,
                                          parameter_session = 1,
                                          scale_session = 1,
                                          parameter = "proportion_good",
                                          scale = scale,
                                          r = curr_cor$Observed,
                                          lower_ci = curr_ci$lower[1],
                                          upper_ci = curr_ci$upper[1]))
      
      curr_data = card_proportions %>%
        filter(stim == card) %>% 
        left_join(sr_sess1) %>%                    # Join scales to orl parameter
        select(-c(sex, race, Ethnicity)) %>%       # Remove columns that we don't need
        na.omit()                                  # Remove rows with NAs
      
      curr_scale = curr_data[[scale]]              # Subset scale data
      curr_estimate = curr_data[["session_2"]] # Subset estimate for parameter
      # Run the boot-strapped correlation between the current scale and the current parameter
      curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                              null.hyp = NULL,
                              alternative = c("two.sided", "less", "greater"),
                              conf.level = 0.95, type = NULL, R = 9999)
      
      curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
        separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
        # Remove parentheses and turn CIs into numerics
        mutate(lower = as.numeric(str_remove(lower, "[(]")),
               upper = as.numeric(str_remove(upper, "[)]")))
      
      # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
      correlations = bind_rows(correlations,
                               data.frame(card = card,
                                          parameter_session = 2,
                                          scale_session = 1,
                                          parameter = "proportion_good",
                                          scale = scale,
                                          r = curr_cor$Observed,
                                          lower_ci = curr_ci$lower[1],
                                          upper_ci = curr_ci$upper[1]))
  }
}
```



### Session 2 Self-Report w/ Session 1 & 2 ORL Parameters
```{r}
for(card in c("A", "B", "C", "D")){
  # Loop through each scale from session 2
  for(scale in c("bastot", "basdrive", "basfunsk",
                 "basrewres", "bis", "panas_pa",
                 "panas_na", "shaps_tot")){
      
      curr_data = card_proportions %>% 
        filter(stim == card) %>% 
        left_join(sr_sess2) %>%                    # Join scales to orl parameter
        na.omit()                                  # Remove rows with NAs
      
      curr_scale = curr_data[[scale]]              # Subset scale data
      curr_estimate = curr_data[["session_1"]] # Subset estimate for parameter
      # Run the boot-strapped correlation between the current scale and the current parameter
      curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                              null.hyp = NULL,
                              alternative = c("two.sided", "less", "greater"),
                              conf.level = 0.95, type = NULL, R = 9999)
      
      curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
        separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
        # Remove parentheses and turn CIs into numerics
        mutate(lower = as.numeric(str_remove(lower, "[(]")),
               upper = as.numeric(str_remove(upper, "[)]")))
      
      # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
      correlations = bind_rows(correlations,
                               data.frame(card = card,
                                          parameter_session = 1,
                                          scale_session = 2,
                                          parameter = "proportion_good",
                                          scale = scale,
                                          r = curr_cor$Observed,
                                          lower_ci = curr_ci$lower[1],
                                          upper_ci = curr_ci$upper[1]))
      
      curr_data = card_proportions %>%             # Subset orl parameter
        filter(stim == card) %>% 
        left_join(sr_sess2) %>%                    # Join scales to orl parameter
        na.omit()                                  # Remove rows with NAs
      
      curr_scale = curr_data[[scale]]              # Subset scale data
      curr_estimate = curr_data[["session_2"]] # Subset estimate for parameter
      # Run the boot-strapped correlation between the current scale and the current parameter
      curr_cor = boot.cor.bca(x = curr_scale, y = curr_estimate,
                              null.hyp = NULL,
                              alternative = c("two.sided", "less", "greater"),
                              conf.level = 0.95, type = NULL, R = 9999)
      
      curr_ci = data.frame(data = curr_cor$Confidence.interval) %>%       # Get the confidence interval of the current correlation (this is a string)
        separate(col = data, sep = ",", into = c("lower", "upper")) %>%   # Separate confidence interval string into lower and upper CI columns
        # Remove parentheses and turn CIs into numerics
        mutate(lower = as.numeric(str_remove(lower, "[(]")),
               upper = as.numeric(str_remove(upper, "[)]")))
      
      # Bind the current correlation to the correlations dataframe while also detailing what the correlation is from (e.g., session, parameter, etc.)
      correlations = bind_rows(correlations,
                               data.frame(card = card,
                                          parameter_session = 2,
                                          scale_session = 2,
                                          parameter = "proportion_good",
                                          scale = scale,
                                          r = curr_cor$Observed,
                                          lower_ci = curr_ci$lower[1],
                                          upper_ci = curr_ci$upper[1]))
  }
}
```



## Format Correlations
### By Session
```{r}
formatted_correlations = correlations %>% 
  # Identify CIs that DO NOT overlap with 0
  mutate(sig = case_when(lower_ci < 0 & upper_ci < 0 ~ "*",
                         lower_ci > 0 & upper_ci > 0 ~ "*",
                         T ~ ""),
         # Format numerics
         r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = "."),
         lower_ci = str_replace(format(round(lower_ci, 2), nsmall = 2), "0.", replacement = "."),
         upper_ci = str_replace(format(round(upper_ci, 2), nsmall = 2), "0.", replacement = "."),
         # Concatenating correlations and CIs
         estimate = paste(r, " (", lower_ci, ", ", upper_ci, ")", sig,
                          sep = "")) %>% 
  select(-c(sig, r, lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = c("parameter", "parameter_session", "scale_session"), values_from = estimate,
              values_fill = "")

write.csv(formatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "card_proportion_formatted_correlations.csv"))
```



### Overall
```{r}
formatted_correlations = overall_correlations %>% 
  # Identify CIs that DO NOT overlap with 0
  mutate(sig = case_when(lower_ci < 0 & upper_ci < 0 ~ "*",
                         lower_ci > 0 & upper_ci > 0 ~ "*",
                         T ~ ""),
         # Format numerics
         r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = "."),
         lower_ci = str_replace(format(round(lower_ci, 2), nsmall = 2), "0.", replacement = "."),
         upper_ci = str_replace(format(round(upper_ci, 2), nsmall = 2), "0.", replacement = "."),
         # Concatenating correlations and CIs
         estimate = paste(r, " (", lower_ci, ", ", upper_ci, ")", sig,
                          sep = "")) %>% 
  select(-c(sig, r, lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = "parameter", values_from = estimate,
              values_fill = "")

write.csv(formatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "card_proportion_formatted_overall_correlations.csv"))
```



## Unformatted Correlations
```{r}
unformatted_correlations = correlations %>% 
  # format correlations
  mutate(r = str_replace(format(round(r, 2), nsmall = 2), "0.", replacement = ".")) %>% 
  select(-c(lower_ci, upper_ci)) %>% 
  pivot_wider(names_from = c("parameter", "parameter_session", "scale_session"), values_from = r,
              values_fill = "")

write.csv(unformatted_correlations, here("1_IGT_PP", "Figs_Tables", "Summary_Score_Correlations", "card_proportion_unformatted_correlations.csv"))
```



# -----------------------------------------------






















